<div class="col-md-3 col-md-push-9 hidden-xs hidden-sm">
    <div id="sidebar">
        <div class="sidebar-toc" style="margin-bottom: 20px;">
            <p class="toc-header">Contents</p>
            <div id="toc"></div>
        </div>
        <div id="search">
            <script>
                (function() {
                    var cx = '010264411143030149390:ajvee_ckdzs';
                    var gcse = document.createElement('script');
                    gcse.type = 'text/javascript';
                    gcse.async = true;
                    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
                            '//cse.google.com/cse.js?cx=' + cx;
                    var s = document.getElementsByTagName('script')[0];
                    s.parentNode.insertBefore(gcse, s);
                })();
            </script>
            <gcse:searchbox-only></gcse:searchbox-only>
        </div>
    </div>
</div>

<div class="col-md-9 col-md-pull-3">

    <h1 id="linear-algebra-top" class="title">Linear Algebra</h1>

    <p>Smile Shell provides an MATLAB like environment.
        In the simplest case, you can use it as a calculator.</p>

    <pre class="prettyprint lang-scala"><code>
    smile&gt; "Hello, World"
    res0: String = Hello, World

    smile&gt; 2
    res1: Int = 2

    smile&gt; 2+3
    res2: Int = 5
    </code></pre>

    <h2 id="functions" class="title">Math Functions</h2>

    <p>All <code>java.lang.Math</code> functions are imported in the Shell.</p>

    <pre class="prettyprint lang-scala"><code>
    smile&gt; log(2)
    res0: Double = 0.6931471805599453

    smile&gt; max(2, 5)
    res2: Int = 5
    </code></pre>

    <p>In addition, Smile provides many other important mathematical functions
        such as <code>logistic</code>, <code>factorial</code>, <code>choose</code>, etc.</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; logistic(3.0)
    res7: Double = 0.9525741268224334

    smile&gt; choose(10, 3)
    res8: Double = 120.0
    </code></pre>

    <h2 id="special" class="title">Special Functions</h2>

    <p>Special mathematical functions including <code>beta</code>,
        <code>erf</code>, <code>gamma</code> and their related functions. Special
        functions are particular mathematical functions which have more or less
        established names and notations due to their importance in mathematical
        analysis, functional analysis, physics, or other applications.
        Many special functions appear as solutions of differential equations or
        integrals of elementary functions. For example, the error function
        <code>erf</code> (also called the Gauss error function) is a special
        function of sigmoid shape which occurs in probability, statistics, materials
        science, and partial differential equations. The complementary error function,
        denoted <code>erfc</code>, is defined as <code>erfc(x) = 1 - erf(x)</code>.
        The error function and complementary error function are special cases of the
        incomplete gamma function.</p>

    <pre class="prettyprint lang-scala"><code>
    smile&gt; erf(1.0)
    res0: Double = 0.8427007929497149

    smile&gt; digamma(1.0)
    res11: Double = -0.5772156649015328
    </code></pre>

    <h2 id="vector" class="title">Vector Operations</h2>

    <p>Common arithmetic operations on vectors and scalars are similar as in R and Matlab.</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; val x = c(1.0, 2.0, 3.0, 4.0)
    smile&gt; val y = c(4.0, 3.0, 2.0, 1.0)

    smile&gt; x + y
    res22: smile.math.VectorAddVector = Array(5.0, 5.0, 5.0, 5.0)

    smile&gt; 1.5 * x - 3.0 * y
    res24: smile.math.VectorSubVector = Array(-10.5, -6.0, -1.5, 3.0)
    </code></pre>

    <p>Note that these operations are lazy. The computation is only performed when
        the results are needed, e.g. when the expression is used where a vector is expected.
        In the Shell, the expression is immediately performed because the Shell
        always prints out the results.</p>

    <p>For a vector, there are multiple functions to calculate its norm such as <code>norm</code> (L2 norm), <code>norm1</code> (L1 norm),
        <code>norm2</code> (L2 norm), <code>normInf</code> (infinity norm), <code>normFro</code> (Frobenius norm).
        We can also <code>standardize</code> a vector to mean 0 and variance 1,
        <code>unitize</code> it so that L2 norm be 1,
        or <code>unitize1</code> it so that L1 norm be 1.</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; norm(x)
    res13: Double = 5.477225575051661

    smile&gt; unitize(y)
    smile&gt; y
    res14: Array[Double] = Array(0.7302967433402214, 0.5477225575051661, 0.3651483716701107, 0.18257418583505536)
    </code></pre>

    <p>For a pair of vectors, we can calculate the dot product, distance, divergence, covariance,
        and correlations with <code>dot</code>, <code>distance</code>, <code>kld</code> (Kullback-Leibler Divergence),
        <code>jsd</code> (Jensen-Shannon Divergence), <code>cov</code>, <code>cor</code> (Pearson Correlation),
        <code>spearman</code> (Spearman Rank Correlation Coefficient), <code>kendall</code> (Kendall Tau Rank Correlation Coefficient).</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; dot(x, y)
    res16: Double = 20.0

    smile&gt; cov(x, y)
    res17: Double = -1.6666666666666667
    </code></pre>

    <h2 id="matrix" class="title">Matrix Operations</h2>

    <p>Like Matlab, we can use <code>eye</code>, <code>zeros</code> and <code>ones</code>
        to create identity, zero, or all-ones matrix, respectively.
        To create a matrix from 2-dimensional array, we can use the constructor <code>matrix</code>
        or the <code>~</code> operator.
        The <code>~</code> operator can be applied to 1-dimensional array too, which creates
        a single column matrix.</p>

    <pre class="prettyprint lang-scala"><code>
    val a = matrix(
        c(0.7220180, 0.07121225, 0.6881997),
        c(-0.2648886, -0.89044952, 0.3700456),
        c(-0.6391588, 0.44947578, 0.6240573)
    )
    val b = matrix(
        c(0.6881997, -0.07121225, 0.7220180),
        c(0.3700456, 0.89044952, -0.2648886),
        c(0.6240573, -0.44947578, -0.6391588)
    )
    val C = Array(
        Array(0.9527204, -0.2973347, 0.06257778),
        Array(-0.2808735, -0.9403636, -0.19190231),
        Array(0.1159052, 0.1652528, -0.97941688)
    )

    val c = ~C // or val c = matrix(C)
    </code></pre>

    <p>Matrix-vector operations are just like in math formula.</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; a * x + y * 1.5
    res26: smile.math.VectorAddVector = Array(4.024486715010331, -0.11406700374225098, 2.6796872175051663)
    </code></pre>

    <p>Similarly for matrix-matrix operations:</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; a + b
    res27: smile.math.MatrixAddMatrix =
        1.4102    0.0000    1.4102
        0.1052    0.0000    0.1052
       -0.0151    0.0000   -0.0151
    </code></pre>

    <p>Note that <code>a * b</code> are element-wise:</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; a * b
    res28: smile.math.MatrixMulMatrix =
        0.4969   -0.0051    0.4969
       -0.0980   -0.7929   -0.0980
       -0.3989   -0.2020   -0.3989
    </code></pre>

    <p>For matrix multiplication, the operator is <code>%*%</code>, same as in R</p>
    <pre class="prettyprint lang-scala"><code>
    smile&gt; a %*% b %*% c
    [main] INFO smile.math.MatrixOrderOptimization - The minimum cost of matrix multiplication chain: 54
    res29: smile.math.MatrixExpression =
        0.9984    0.0067    0.0554
       -0.0257    0.9361    0.3508
       -0.0495   -0.3517    0.9348
    </code></pre>

    <p>The method <code>DenseMatrix.transpose</code> returns the transpose of matrix,
        which executes immediately. However, the method <code>t</code> is preferred
        on <code>MatrixExpression</code> as it is lazy.</p>

    <pre class="prettyprint lang-scala"><code>
    smile&gt; a %*% b.t %*% c
    [main] INFO smile.math.MatrixOrderOptimization - The minimum cost of matrix multiplication chain: 54
    res30: smile.math.MatrixExpression =
        0.8978   -0.4369    0.0543
        0.4189    0.8856    0.2006
       -0.1357   -0.1574    0.9782
    </code></pre>

    <p>Smile has runtime optimization for matrix multiplication chain, which can greatly
        improve the performance. In the below we generate several random matrices and multiply
        them together.</p>

    <pre class="prettyprint lang-scala"><code>
    val a = randn( 300,  900)
    val b = randn( 900,  150)
    val c = randn( 150, 1800)
    val d = randn(1800,   30)

    time {(a %*% b %*% c %*% d).toMatrix}
    </code></pre>

    <p>where <code>randn()</code> creates a matrix of normally distributed
        random numbers. The shell will try to load machine optimized
        BLAS/LAPACK native libraries for most matrix computation.
        If BLAS/LAPACK is not available, smile will fall back to pure Java
        implementation.</p>

    <h2 id="decomposition" class="title">Matrix Decomposition</h2>

    <p>In linear algebra, a matrix decomposition or matrix factorization
        is a factorization of a matrix into a product of matrices.
        There are many different matrix decompositions. In Smile, we provide
        LU, QR, Cholesky, eigen, and SVD decomposition by functions
        <code>lu</code>, <code>qr</code>, <code>cholesky</code>,
        <code>eigen</code>, and <code>svd</code>, respectively.</p>

    <p>With these decompositions, many important linear algebra operations
        can be performed such as calculating matrix rank, determinant, solving
        linear systems, computing inverse matrix, etc.
        In fact, Smile has functions <code>det</code>,
        <code>rank</code>, <code>inv</code> and operator <code>\</code>
        for these common computation.</p>

    <pre class="prettyprint lang-scala"><code>
    smile&gt; val x = Array(1.0, 2.0, 3.0)
    x: Array[Double] = Array(1.0, 2.0, 3.0)

    smile&gt; a \ x
    res14: Array[Double] = Array(-1.7252356779053744, -0.3612592362819077, 3.3004624918302046)

    smile&gt; inv(a)
    res19: smile.math.matrix.DenseMatrix =
      0.7220   -0.2649   -0.6392
      0.0712   -0.8904    0.4495
      0.6882    0.3700    0.6241
      smile&gt; inv(a) %*% a

    res21: smile.math.MatrixExpression =
      1.0000    0.0000    0.0000
     -0.0000    1.0000    0.0000
     -0.0000    0.0000    1.0000
    </code></pre>

    <div id="btnv">
        <span class="btn-arrow-left">&larr; &nbsp;</span>
        <a class="btn-prev-text" href="manifold.html" title="Previous Section: Manifold Learning"><span>Manifold Learning</span></a>
        <a class="btn-next-text" href="statistics.html" title="Next Section: Statistics"><span>Statistics</span></a>
        <span class="btn-arrow-right">&nbsp;&rarr;</span>
    </div>
</div>

<script type="text/javascript">
    $('#toc').toc({exclude: 'h1, h5, h6', context: '', autoId: true, numerate: false});
</script>
